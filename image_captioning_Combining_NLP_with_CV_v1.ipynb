{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2x2kU_nYg3-"
   },
   "source": [
    "# ðŸ“š Image Captioning Challenge ðŸ“š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFjMUTnqZbrv"
   },
   "source": [
    "## 0-Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TC3H3yLIZgK3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from numpy import cov, trace, iscomplexobj\n",
    "from scipy.linalg import sqrtm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvTYXkOzsTQe"
   },
   "source": [
    "## 1- Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xAT5w6IYYt-l",
    "outputId": "204b4351-8a8a-4726-aba6-a016cdf66930"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!unzip \"/content/drive/MyDrive/caption_dataset/caption_dataset.zip\" -d \"/content/dataset/\"\n",
    "\n",
    "train_df = pd.read_csv(\"/content/dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"/content/dataset/test.csv\")\n",
    "sample_df = pd.read_csv(\"/content/dataset/sample_submission.csv\")\n",
    "\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "M2mytGwXY-h-",
    "outputId": "6aba9676-cb20-4ea4-dda1-37b45cb40b8a"
   },
   "outputs": [],
   "source": [
    "train_df['caption_length'] = train_df['caption'].apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(train_df['caption_length'], bins=30, kde=True)\n",
    "plt.title(\"Caption Length Distribution\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "print(\"Unique captions:\", train_df['caption'].nunique())\n",
    "print(\"Average caption length:\", train_df['caption_length'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "7AXBt6CDpuS2",
    "outputId": "006e933e-7bef-4e67-997a-5866ca4efc79"
   },
   "outputs": [],
   "source": [
    "def show_random_examples(df, n=5):\n",
    "    fig, axes = plt.subplots(1, n, figsize=(15, 5))\n",
    "    for i in range(n):\n",
    "        row = df.sample(1).iloc[0]\n",
    "        img_filename = f\"{row['image_id']}.jpg\"\n",
    "        img_path = f\"/content/dataset/train/train/{img_filename}\"\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Image not found: {img_path}\")\n",
    "            continue\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(\"\\n\".join(row['caption'].split()[:8]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_random_examples(train_df, 5)\n",
    "show_random_examples(train_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZB4_XKbup2X8",
    "outputId": "a7a5eb22-92ac-4185-8396-987dc010b7a5"
   },
   "outputs": [],
   "source": [
    "print(\"Unique captions:\", train_df['caption'].nunique())\n",
    "print(\"Average caption length:\", train_df['caption_length'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKzn90NisXtx"
   },
   "source": [
    "## 2- Data Preprocessing and Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297,
     "referenced_widgets": [
      "290c754a523c403690810dff83e3fa1d",
      "49dfae3508fd45f296abc2369a8f36da",
      "9d71011451ad463aa05dc47906189479",
      "36947bf9afb04860b79d1863caf25e6d",
      "ff1cfff86ffa42f2bf6645b5e77f2368",
      "224cd7f587db460286d45e5fbea21d6d",
      "62031f90156949da8964306121652fb0",
      "bb300db64a254f3d8dc1e5fc01d6c25a",
      "5344d95b01454b2889ecc46bb776187a",
      "a73b1edacbc24b9e8bf53ac8b403eff3",
      "ba58d92e002f4f8792ac201fa4cccf66",
      "d003d13d0f844b1c8620c6766edd948b",
      "249a0db4ba76448e934c306e57e7ab74",
      "7379bdabf0984566a27f760e6d36cd3e",
      "542b71d99a7f4891a805ddb882c87906",
      "2a4dfd46811c4a7d854f3c96d9df3469",
      "f46ff6f4cadc4b5a80c163741a086331",
      "d4f6905af7854225ad421e6c946ebb8c",
      "4439c43bba4849dca09c7cd59e05445d",
      "1eba99b8b5ca4024a983bafffc5c0157",
      "4160e6488c514dc5823194c5331cbee4",
      "dd26e3097922417097bbb08ebb4ae37b",
      "ce1c5df188434b20b5fa0e37dd85aea3",
      "d17ea549c715441d8b904a06ee7128c7",
      "20477ba9ede749b2889df0f68a962008",
      "c4c08b9d9026482388fb6e756267523a",
      "66f80a4e3d9940e7b660cf5888f25eda",
      "e5098eddc0da47fb804c812ee105621b",
      "fe43647fa85a447083e33061d0b5f518",
      "0ced85bf2bee45bcaef97a4c3e6b0ac1",
      "cc6b56f9aba24fcc80cf032ca48609a2",
      "a15659d945bb4642bbd843ba13fa1ec3",
      "a1b585d5246a4345ad7e12676b41fbd5",
      "3d4faa50448045babb890894381c1879",
      "058e5809206c48cdb8747b6ec615acb4",
      "0011862919d24f558722d10b14aa1d49",
      "88af26ae08594b8a857a983c788ceed6",
      "7a04eb2edaff46c3be002bb173b685d5",
      "5572ccc620d341ce96d0148c9608ff75",
      "1fcee5cb78514acb8feb764aafaef38a",
      "d68594a50807402ca710fce8bdd1fcd6",
      "9e7118f86757404ea820d6a897013a87",
      "339058f2f8aa4d9eb6295655f554e2f4",
      "e82f26011ef84e318dd3ea6034d5d14f",
      "18e64eae09624ed0b2a9fea757aaff02",
      "ee59907b7b2646b79e0052c817d0ed23",
      "eedd27680c9f4fb6a5b3b74350b8370a",
      "6372214c768947c4acb66ec8006e5162",
      "e400ba753d9046abad8106ad63a0f3bc",
      "29bd2aa84dbb4a9d80f12f2b199aeac7",
      "5bce0420a1cb42849078a0ff556c3aef",
      "6f4639e00e0c454c9f9c945a8c10d92c",
      "00708bd538f44e0b8f4f1659515b7cfd",
      "40fcd8f2437045708c1d0d069070787c",
      "a5a1ea1419164cfd977485bfc90dba93",
      "f60e4afe6378408497c330eb4084e885",
      "1528e4feaf424bbb84e85d0103f3259c",
      "aac43ffde3c04173b403a4d9c41affba",
      "d8d46f3691d641ceab43eef6a2d36620",
      "9f2242a61a954410ae9a2f4451791c9a",
      "ba702c10ddf24a86843078e8500568ec",
      "1bdc1985f9e1478ab042020ee4e5b13e",
      "de47a80e7a3b4335beb7929242e4bf38",
      "765621e519ff44c7adecc4a0549ca828",
      "053c9356fd6a4137a1289488ce8b4f0e",
      "5434e7c82cf2412abe9418dd511b1aac",
      "e5467989c3b5487db5c360b4732ba4ec",
      "2a99245fe2154e2ba050b9d9a31fa811",
      "211006f7331246cea3193ad04e9b3178",
      "9448ea8a67e542c7975da15ef0ccf950",
      "7246963e93334b1e822b2da688f5b02a",
      "310989a37ca9414fb7776dd73a598eb3",
      "43cd727a1d84431b97101a947d417199",
      "83b5aa07fbfe4d679eb126524e6e0460",
      "ce17b9f92b22432bad9c244fe749232a",
      "a92c8deebe5d429bb98f10e8446ce8fe",
      "85e74099f2c3452cb48869d97c7b2a24"
     ]
    },
    "id": "7E-KmQLPZS_m",
    "outputId": "ccf074af-723d-420d-b2ef-4e9a447797b0"
   },
   "outputs": [],
   "source": [
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "train_df['caption_proc'] = train_df['caption'].apply(lambda x: \"<start> \" + x.strip() + \" <end>\")\n",
    "\n",
    "blip_model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\",\n",
    "                                                           device_map=\"auto\", # distrubute CPU/GPU\n",
    "                                                           torch_dtype=torch.float16)# float16 for Vram\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "p1YZG-mEZy-S",
    "outputId": "2f941a6b-6687-4b7f-800c-7c7ff667b560"
   },
   "outputs": [],
   "source": [
    "# Create example caption\n",
    "sample_row = test_df.sample(1).iloc[0]\n",
    "sample_img_id = str(sample_row['image_id'])\n",
    "if not sample_img_id.endswith(\".jpg\"):\n",
    "    sample_img_id += \".jpg\"\n",
    "img_path = f\"/content/dataset/test/test/{sample_img_id}\"\n",
    "\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device, dtype=torch.float16) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_ids = blip_model.generate(**inputs, max_new_tokens=30, do_sample=False)\n",
    "caption = processor.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"ID: {sample_img_id}\\nCaption creation example from test set:\\n\\n{caption}\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH8cCyaVtQ7R"
   },
   "source": [
    "## 3-Creating Captions For submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "lyhphGi5dnz9",
    "outputId": "191a51f9-d26d-4446-db97-071016fdf63b"
   },
   "outputs": [],
   "source": [
    "submission = []\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    img_id = str(row[\"image_id\"])\n",
    "    if not img_id.endswith(\".jpg\"):\n",
    "        img_id += \".jpg\"\n",
    "    img_path = f\"/content/dataset/test/test/{img_id}\"\n",
    "    try:\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Image not found or corrupted: {img_path}\")\n",
    "        continue\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device, dtype=torch.float16) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        generated_ids = blip_model.generate(**inputs, max_new_tokens=30, do_sample=False)\n",
    "    caption = processor.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    submission.append({\"image_id\": img_id, \"caption\": caption})\n",
    "\n",
    "submission_df = pd.DataFrame(submission)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35RWbbQge59y"
   },
   "source": [
    "## 5- CALCULATE FGD SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575,
     "referenced_widgets": [
      "f2abd1f20b1e488192f0addc4a1f3bb4",
      "68bd8291d3c94cf182d713ac2a621c0c",
      "22bb2efc28c6441c8520f72d81702269",
      "e54c89e5bed34cf2bc4e452cf2d1e674",
      "4f247f0dfd234256941013136a77bf71",
      "5fbf7e75a7ff4e8cb7dc222f7252801d",
      "3877797513c54d23b94cf363f3403262",
      "9d334a1cc97e48f599ad6df4c0e44073",
      "d63111bfc558403facf43f15cb1f0925",
      "a61eb6dd90f94b16b89643792ccec559",
      "553d2f4e448f44aaac01024692672820",
      "8b4b9d5b8c3648dfb8c4d8eaa40065e0",
      "db282873cb8144458c0c3402da5732b0",
      "a549ad3ae59e4a45853fcc89406e6101",
      "473c95f27f81496e8ec4b115ad616a4b",
      "b0d528b815be4d5b9749618b0ed0cda3",
      "3c5d8560d8144f1e9d81b48b7d502b57",
      "a07537a753544cc8b43515c230331a91",
      "f6f27d04778b47b5ac28c81bd41dc7fa",
      "3ca56b05414442a39293da4aca8a5f7e",
      "221f2613064344008be4dda2e6e04b75",
      "2e309b6b09b34178ba98108f01443039",
      "bd8aa9d8787a4127b4f327dfceb8aae7",
      "4faa0d0bee2547768ff9415ffcb55c3a",
      "faaae1735a304a31a79412bf950bdd43",
      "43f398c426304c23a6bcf7621a350b0d",
      "48aa13ab80e745e3905dd39db1c4a821",
      "0efe2d54f5184e1eaa569356d8ddbea7",
      "8a9a5f363b5348e3ae082c26f6b9b93b",
      "f00c7bca1b71450584322e48196702a3",
      "43cfa75afc9d4c94b0b81cefcfdaed50",
      "1735471012ae45a090adf08d72ac3339",
      "03ecbbbd7eac49a18780f96042fc8a6a",
      "a47fbdc5b156431fafb28404c55fa2e9",
      "af9a353d7c7f4d6e997841ebba334d99",
      "09f2f2f0967c480a93019543b12ca692",
      "61272be18c2b400e9293926de99cbfc7",
      "794a9defc80f45d39ed49f8b345587ac",
      "7f328716c50a434fa94f418ec7636705",
      "798853951b23435f9a8a3f2e4563c7e9",
      "72bc4e171dfd434f9e9327fd4d7083fb",
      "a665b3da83264a9db3706043dfe203fd",
      "4501e14daf0441f8ae9f373b482ed0a9",
      "967a7d387eba4e109ba91b6045f678b9",
      "aa5fe75fb7d94cda85c79715c7291bf9",
      "f2f0679751314bfe8c748165691ab608",
      "3fbc7e95797c43088e4207f1b9f3e7bf",
      "fdaa050dba8d407189dda3160525ae70",
      "a496b8601e964a8b9171d3b64fa96795",
      "e5756e72562a4e7cba68671d1a3bab0f",
      "0995114c0e884f44a6189e487332041f",
      "0b22115506b84fe783ffaf5e9efd0e6c",
      "32e1971afb844589b8212d58c7eb2951",
      "0b0bccdbdf4f44bb850a80024e48e830",
      "db65e2085c1e4ace9489606212cfee62",
      "932bbace6c5d4e8ba0b2526cc390685c",
      "2a2bbec9205044ce92bac10520ecb889",
      "fec241858a464d3da783ac39b0fffe2b",
      "e7948df3a03f440a928aa24394164c60",
      "93f696c1bd814419b8fc85ebe4525523",
      "8803218f56cd49a89b368ed9cb251812",
      "d1b9e9ef46c04664a0f9352656b3e996",
      "edfa2847afa448dab1a0846d2b5950ed",
      "423cdaef6b394fa890e2725b4fd22a72",
      "dd07a67fedac449f97376eca7c116ae0",
      "7494164a22844473a062bcb20452ad3a",
      "8dd3ec2ba03145d6943bebd4f1314cf8",
      "d0e5e40f346847f08f50246a8153c257",
      "eb34b5c0463345df81b9a309ad5e0844",
      "c2bb50c2ae0745e98a06448f313b3b30",
      "9c1f2f9aa6ce47eaa5ce02afc3116499",
      "ef39a851022e499096e1ca5798d6463a",
      "6783ec407ba249d6b0a04c4aad261ad2",
      "fab6011e22ee4bd5816801e097cdaff5",
      "ac38d4f13621415fba88723bfa2895b5",
      "6eb660f434cb4fd7a2d47db6955d8288",
      "af6ffd2ed0a5424c8a15060308294c4d",
      "1e1ec90c9efc4a36bfbb239ce21d33b2",
      "ed1234a0a05247a091f53919a405b91d",
      "18dc1e63beb24a3daf858495673d7284",
      "27dab4d2f0e141b7858a89d7f0769ef1",
      "5be2ab1905394da89d499196cf586cd9",
      "714297e9d0f14aea8a225f956439c069",
      "274d29bcbff341298515d5e62bd21cc4",
      "1cba8eb8532c42a7b8189d70eeab1a21",
      "3e4b4b4746c64c1fb92d80f8dc066910",
      "5426ca4a2c794f8b9b4923693d162017",
      "0f72d01d428344808178c57d0d470489",
      "83473b5cb0fa4d0084648344ae465d75",
      "23313f106082425f84386e2661b872ba",
      "3ede78d596054c2c9c64b424f38d8bc8",
      "474797d9da1145e08977ba50bc72642e",
      "8ce7319ccbb241d5b0ca8428cfbc5a13",
      "0f978d9c571e42068e4d30113b7ad80c",
      "4d52f057c5ea4e63a737ba6e1cdc1d5c",
      "9eb822679cd84af8a230eacd757d8192",
      "438e760d5a96431a810a465586d7984f",
      "c5aad18c4df44e08a7933909deffd9a3",
      "d246439542774825973bedfd5914d057",
      "3ff302d107484089b73c9772de1e909c",
      "a65f4c5e530d45719dd9e5113b325b72",
      "3a43c802940a43dab1725b8c21f8ef48",
      "927ee2951d224af98e962b0ae44d013b",
      "3f9f2921b1bb49978f2f767813c60699",
      "994b48990330407bbef9bc50372f9167",
      "02aafa49e5ab4fc29b0efe1772078b46",
      "e6f52d4934dc4feabb91b9cc26d604df",
      "049d85c9905c4bc2bb1e9ebd1f876601",
      "b1fe0ea194434aaaa3c7674b4be431a3",
      "4356c9b75bfd4b4b81b9d3aad60b1d3a",
      "804d04bd2fcd418c97fb497a1fbd5348",
      "a0222affbaf34cb6b7077e107f0a1718",
      "59dc440dd4714a30b5e9b832472fea0d",
      "58773dc542c1459083db064a11f57b7b",
      "afa2da57183549dfa708a8ba0f95efde",
      "659671296d0d483ebb4605133311bb6f",
      "47d40a33315c43188bcfb68b8a8cc901",
      "f0b8a84020604ed8905f1d3da89119fa",
      "d59e93cf4f2a4a3a97422c2770d6f669",
      "54f51708f4374079a8c3cfd262605eea",
      "843236b1fb674126977a2a4b30ddf92f",
      "e8d9d25e070a4c7e9bf20412c799a5dc",
      "36f8cac9b18a47a69f654ea663c805c3",
      "8ccd3f3772114b18903fb2a23f953fea",
      "30aea71f708d4a729f8f66be9550d69e",
      "0183256fdec84602a679fc3241ce1d7f",
      "833a9ed6a52e4d69ae7082ea1046e9f0",
      "a169faadae2b408db6bdf73982c68ea6",
      "6a8e216fad2a4762bd8f7da9026ec3c5",
      "ce56036b36384a6790e1b5d2d674528b",
      "3c2f4f2537594436be3f738460cb2705",
      "0d03e428e10749cb9965ff81d7a8df5e"
     ]
    },
    "id": "DLx8oP9qeo-T",
    "outputId": "7aeb6b12-6ae4-46c4-81e0-163e7dc297e1"
   },
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "gte_model = SentenceTransformer(\"thenlper/gte-small\")\n",
    "\n",
    "gt_df = pd.read_csv(\"/content/dataset/train.csv\")\n",
    "pred_df = pd.read_csv(\"submission.csv\")\n",
    "N = min(len(gt_df), len(pred_df))\n",
    "gt_captions = gt_df[\"caption\"].values[:N]\n",
    "pred_captions = pred_df[\"caption\"].values[:N]\n",
    "\n",
    "gt_embed = gte_model.encode(list(gt_captions), batch_size=64, show_progress_bar=True)\n",
    "pred_embed = gte_model.encode(list(pred_captions), batch_size=64, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OolgPvzB1zXI"
   },
   "outputs": [],
   "source": [
    "# Function from the datathon main page\n",
    "def calculate_fgd(solution_embed: np.ndarray, submission_embed: np.ndarray) -> float:\n",
    "    fgd_list = []\n",
    "    for _idx, (sol_emb_sample, sub_emb_sample) in enumerate(zip(solution_embed, submission_embed)):\n",
    "        sol_emb_sample_rshaped = sol_emb_sample.reshape((1,384))\n",
    "        sub_emb_sample_rshaped = sub_emb_sample.reshape((1,384))\n",
    "        e1 = np.concatenate([sol_emb_sample_rshaped, sol_emb_sample_rshaped])\n",
    "        e2 = np.concatenate([sub_emb_sample_rshaped, sub_emb_sample_rshaped])\n",
    "        mu1, sigma1 = e1.mean(axis=0), cov(e1, rowvar=False)\n",
    "        mu2, sigma2 = e2.mean(axis=0), cov(e2, rowvar=False)\n",
    "        ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "        covmean = sqrtm(sigma1.dot(sigma2))\n",
    "        if iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "        fgd = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "        fgd_list.append(fgd)\n",
    "    return float(np.mean(fgd_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwZpsdiK15_t",
    "outputId": "2cd98ec0-2897-43f2-fea4-ed268ae3e487"
   },
   "outputs": [],
   "source": [
    "fgd_score = calculate_fgd(gt_embed, pred_embed)\n",
    "print(f\"\\nFinal FGD Score: {fgd_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
